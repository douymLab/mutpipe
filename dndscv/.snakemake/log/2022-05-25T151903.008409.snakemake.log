Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job                         count    min threads    max threads
------------------------  -------  -------------  -------------
all                             1              1              1
generate_input_persample        1              1              1
merge_input                     1              1              1
total                           3              1              1

Select jobs to execute...

[Wed May 25 15:19:03 2022]
rule generate_input_persample:
    input: demo/input/test.SNV.out, demo/input/test.INDEL.out
    output: demo/test.SNV.input, demo/test.INDEL.input
    jobid: 2
    wildcards: sample=test
    resources: tmpdir=/tmp

[Wed May 25 15:19:03 2022]
Error in rule generate_input_persample:
    jobid: 2
    output: demo/test.SNV.input, demo/test.INDEL.input
    shell:
        cat demo/input/test.SNV.out|while read line; do echo "test $line"; done|sed 's/ /	/g'|cut -f 1,2,3,5,6 >> demo/test.SNV.inputcat demo/input/test.INDEL.out|while read line; do echo "test $line"; done|sed 's/ /	/g'|cut -f 1,2,3,5,6 >> demo/test.INDEL.input
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job generate_input_persample since they might be corrupted:
demo/test.INDEL.input
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2022-05-25T151903.008409.snakemake.log
